K-means聚类算法
1. 概述

K-means聚类算法也称k均值聚类算法，是集简单和经典于一身的基于距离的聚类算法。它采用距离作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。该算法认为类簇是由距离靠近的对象组成的，因此把得到紧凑且独立的簇作为最终目标。

2. 算法核心思想

K-means聚类算法是一种迭代求解的聚类分析算法，其步骤是随机选取K个对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。聚类中心以及分配给它们的对象就代表一个聚类。每分配一个样本，聚类的聚类中心会根据聚类中现有的对象被重新计算。这个过程将不断重复直到满足某个终止条件。终止条件可以是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。

3. 算法实现步骤

1、首先确定一个k值，即我们希望将数据集经过聚类得到k个集合。 

2、从数据集中随机选择k个数据点作为质心。

3、对数据集中每一个点，计算其与每一个质心的距离（如欧式距离），离哪个质心近，就划分到那个质心所属的集合。

4、把所有数据归好集合后，一共有k个集合。然后重新计算每个集合的质心。

5、如果新计算出来的质心和原来的质心之间的距离小于某一个设置的阈值（表示重新计算的质心的位置变化不大，趋于稳定，或者说收敛），我们可以认为聚类已经达到期望的结果，算法终止。

6、如果新质心和原质心距离变化很大，需要迭代3~5步骤。 

K-means术语：

簇：所有数据的点集合，簇中的对象是相似的。

质心：簇中所有点的中心（计算所有点的中心而来）

5. K-means算法优缺点

优点：

1、原理比较简单，实现也是很容易，收敛速度快。

2、当结果簇是密集的，而簇与簇之间区别明显时, 它的效果较好。

3、主要需要调参的参数仅仅是簇数k。

缺点：

1、K值需要预先给定，很多情况下K值的估计是非常困难的。

2、K-Means算法对初始选取的质心点是敏感的，不同的随机种子点得到的聚类结果完全不同 ，对结果影响很大。

3、对噪音和异常点比较的敏感。用来检测异常值。

4、采用迭代方法，可能只能得到局部的最优解，而无法得到全局的最优解。


数据美白whiten函数
白化的目的是去除输入数据的冗余信息。



python下划线命名模式-小结

单前导下划线                _var             命名约定，仅供内部使用。通常不会由python解释器强制执行(通配符导入除外)，只作为程序员的提示

单末尾下划线                var_             按约定使用以避免与python关键字的命名冲突        

双前导下划线                __var            当在类上下文中使用时，触发“名称修饰”。由python解释器强制执行。  
 
双前导和双末尾下划线        __var__          表示python语言定义的特殊方法。避免在你自己的属性中使用这种命名方案。             

单下划线                        _            有时用作临时或无意义变量的名称("不关心")。也表示Python REPL中最近一个表达式的结果
            
